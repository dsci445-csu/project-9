---
title: "Actionable League of Legends Game Outcome Prediction Using Machine Learning Methods"
author: "By Nick Li, Ryan Stevens, Elle Angell, Coleman Garnier"
output:
  ioslides_presentation:
    widescreen: true
    incremental: false
---

## Motivation:
League is the World's Largest E-sport and it's not close.

* 2024 World Finals: 50 million concurrent peak viewership.
* Most active E-sport at CSU
* Many players want to get better

## Research Questions:
1. Which data best accounts for the outcome of a specific match?
2. Is it possible to provide meaningful feedback to a player on a game using a model?

## Data Overview:
* First party source: Riot Games Developer API, patch 25.22 (Nov 1-3, 2025)
* Collected matches and timelines data through Python
* Highly nested
* Focus: average match MMR of 'Diamond II' (top 1.5% skill)

## Our Data:
* 'Small' Dataset n=250 matches (2,500 players)
* 'Medium' Dataset n=5,000 matches (50,000 players)
* 'Large' Dataset n=50,000 (n=500,000 players)

## Timelines vs Matches:
* Timelines data is mostly superior
* Matches data had better performance on preliminary testing
* In the future...

## Data Features:
* Binary classification problem (win/loss)
*talk about the sort of features we have*

## Gold and Wins:
*graph about gold vs duration colored by win*

## Turrets:
*image to illustrate why they are important*
*graph about turrets lost and turret takedowns vs win*
*this is why we removed them from the data*

## The Research:
Nonlinear Models Dominate:

* Gonzalez, 2023, Deep Neural Network: 89.8%
* Zamir et al., 2024, RNN: 86.7%
* Silva et al., 2023, RNN: 73% (at 15m)
* Chen et al., 2021, Log. Regression: 60.24%

## Fitting a GLM
* Using logistic regression to predict game outcome against all of our player performance metrics (minus turrets)
* 70/30 split between our train/test sets
* Built our GLM on the training set and applied to test data
* Result: ~75.1% accuracy- highest of the all the models we built

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(parsnip)
library(tidymodels)
library(fastshap)
df <- read.csv("data/d2_250_performance.csv")
df$win <- as.integer(df$win == "True")
df <- df[df$lane != "NONE", ]
df <- subset(df, select=-turretsLost)
df <- subset(df, select=-turretTakedowns)
df$position = NULL
df$win <- factor(df$win)
X <- model.matrix(win ~ . - 1, data=df)
X <- as.data.frame(X)
y <- df$win

set.seed(67)
nrow <- nrow(df)
index <- sample(1:nrow, size = nrow * 0.7)
X_train <- X[index, ]
y_train <- y[index]
X_test <- X[-index, ]
y_test <- y[-index]

glm <- 
  logistic_reg() %>%
  set_engine("glm", family=binomial()) %>%
  fit_xy(x = X_train, y = y_train)
glm_pred <- predict(glm, new_data = X_test, type="prob")[[".pred_True"]]
glm_pred_class <- ifelse(glm_pred > 0.5, "True", "False")
glm_pred_class <- factor(glm_pred_class, levels = levels(y_test))
print(paste("GLM Test Accuracy: ",mean(glm_pred_class == y_test)))

```


## Fitting an SVM
* Goal: Predict game outcome (W/L) based on player performance metrics
* Metrics: kills, deaths, dragonKills, baronKills, firstBloodKill, firstBloodAssist
* Performance: Accuracy = 0.72, Misclassification Rate: 27.64%
* Confusion Matrix: Accurately vs. Falsely predicted

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(e1071)
library(dplyr)
library(tidyr)
library(tibble)
library(tidymodels)
library(ggplot2)
df <- read.csv("/workspaces/project-9/sample_data/d2_250_performance.csv")
# Predictors
# Source: https://stackoverflow.com/questions/33930188/convert-dataframe-column-to-1-or-0-for-true-false-values-and-assign-to-dataf
X <- df %>%
select(deaths, dragonKills, baronKills, firstBloodKill, firstBloodAssist, kills) %>% 
mutate(firstBloodKill = as.integer(as.logical(firstBloodKill)),
       firstBloodAssist = as.integer(as.logical(firstBloodAssist)))
# Target
y <- as.factor(df$win)
# Split into training and test sets (70 train 30 test)
set.seed(67)
nrow <- nrow(df)
split_data <- sample(1:nrow, size = nrow * 0.7)
X_train <- X[split_data, ]
y_train <- y[split_data]
X_test <- X[-split_data, ]
y_test <- y[-split_data]
# Scaling X
# Source: https://stackoverflow.com/questions/57421329/how-to-scale-test-data-with-respect-of-train-data
X_train_scaled = scale(X_train)
X_test_scaled = scale(X_test,
                      center = attr(X_train_scaled, "scaled:center"),
                      scale = attr(X_train_scaled, "scaled:scale"))
# Convert to df to train on svm
df_train <- data.frame(y = factor(y_train), X_train_scaled)
df_test <- data.frame(X_test_scaled)
# Train svm
svm_model <- svm(y ~ ., data = df_train, kernel = "radial")
y_pred <- predict(svm_model, newdata = df_test)
# Accuracy 
eval_df <- tibble(
  win = factor(y_test),
  .pred_class = factor(y_pred)
)
svm_accuracy <- accuracy(eval_df, truth = win, estimate = .pred_class)$.estimate
print(paste("SVM Accuracy: ", sprintf("%1.2f", svm_accuracy)))
# Confusion matrix to check accuracy
conf_matrix <- table(predicted = y_pred, actual = y_test)
print("Confusion Matrix: ")
print(conf_matrix)
# misclassifcation rate: % of wrong predictions
misclass_rate <- mean(y_pred != y_test) * 100
print(paste("Misclassification Rate: ", sprintf("%1.2f", misclass_rate)))
```
## Fitting a Random Forest

## RF Influential Predictors

## What is SHAP?

## SHAP on Random Forest

## Interpreting Results
*give a live example of how you can interpret results for a specific sample*

## SHAP Real Example
*feed the model a game one of us played*

## Results

- GLM achieved **75.1%** accuracy  
- Random Forest: **74.7%** accuracy
- SVM: **72.0%** accuracy  
- Consistent top predictors: **deaths**, **goldEarned**  
- Lowest predictors: **first blood–related stats**
- ***graph???

## Discussion

- **GoldEarned** → leads to item power → greater access to victory conditions  
- **Deaths** → enemy gold + **loss of tempo** (6–56 seconds downtime)  
- First blood metrics → minimal long-term predictive value  


## Conclusion

- Pipeline integrates **ML models + SHAP** for interpretable insights  
- High predictive performance across all three models  
- Influential factors: **gold**, **kills**, **deaths**, **vision control**  
- First blood → not influential  

- Supports esports analytics, automated coaching, personalized tools

## Future Work

## References

https://x.com/lolesports/status/1859295721956024521
