---
title: Actionable League of Legends Game Outcome Prediction Using Machine Learning Methods
author: "Ryan Stevens, Elle Isabel Angell, Nick Lee, Coleman Garnier"
output:
  pdf_document: default
  html_document:
    css: styles.css
---

---

## Abstract
<div class="abstract">
  This project assesses multiple different ML approaches (GLM, SVM, RF) to create stable models across multiple cross validation folds that inform over 75% predictive success on our sample data.[Elaborate on results]
  
  
</div>
## 1. Introduction

The game being focused on for this project is League of Legends, a complex, competitive 5v5 multiplayer online battle arena (MOBA) game. The company that created League of Legends, Riot Games, provides high-quality data through its API, gaining access to game data such as player performance and objectives. While there are existing websites to track player statistics such as match history and specific counter pick options, they mainly focus on surface-level statistics and outcomes, not how one’s decisions can influence the result of the game.

The main focus of this project is to analyze and interpret player behavior and decision-making to determine how these patterns may impact the outcome of the game. By examining factors such as participation levels, whether their team had more objectives, and experience/gold levels over the course of the game, key behavioral patterns and the player’s impact on the game can be interpreted and identified.


## 2. Methods and Analysis

## 2.1 Data
All data was gathered through the Riot games developer API on patch 25.22, November 1st through 3rd, 2025. This was accomplished using a data collector written in python that collected corresponding game data from two different api endpoints. First, the Riot match data, which is composed of end-of-game summary statistics. This includes which team won the match, the characters (or Champions) played by each team, the ending gold quantity for each team, and other descriptive statistics. Second, the Riot timeline data, which includes snapshots of the game state in one-minute intervals throughout the match. This data includes (for every minute in the game) information such as the position of each player or inventory of each player. Finally, all data was collected from games played where the average MMR (match making rating) of the participating players was 'Diamond II', which consists of players in approximately the top 1.5% of skill. The primary motivation for this choice was to focus on high-quality yet still plentiful match data. Had a lower skill bracket been selected, the results would be less interpret-able within the context of an organized environment. Had a higher skill bracket been selected, data sparsity would have likely become a problem.

Using the data described above, three primary data sets were collected for modelling and exploring data. First, a small set of n=250 matches (2,500 total players) was used for general data analysis and data exploration this was the 'small dataset'. Second, a larger set of n=5,000 (50,000 total players) made up the 'large dataset'. Both the small and large datasets consist of combined match and timeline data. Finally, a matches-only dataset n=50,000 (500,000 total players) collected on the "Diamond IV" skill bracket was used to gain insights on the impact of team composition on the overall win but did not directly contribute to our results.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(knitr)

kable(
  data.frame(
    Data = c("Small Dataset", "Large Dataset", "Matches Dataset"),
    Size = c("n=250 (2,500 players)",
             "n=5000 (50,000 players)",
             "n=50,000 (500,000 players)"),
    Type = c("Matches, Timelines",
             "Matches, Timelines",
             "Matches")
  ),
  format = "latex",
  booktabs = FALSE,
  caption = "Datasets"
)

```


## 2.2 Preprocessing
The Riot Games developer API returns a highly nested sequence of DTOs (Data Transfer Objects). These structures contain match level, team level, as well as player level level data embedded within multiple, tightly coupled transfer layers, requiring complicated extraction before modeling. All desired JSON responses were flattened into a simpler form by isolating the relevant participant objects and merging them with corresponding match metadata. To accomplish this, data was cleaned using a python script.

## 2.3 Model Evaluation
Among studies published performing similar League of Legends prediction tasks with similar datasets, top performing models typically  used some sort of nonlinear architecture such as an RNN [4], or other form of deep neural network [3]. However, such an approach is not acceptable for our purposes as the extra predictive power comes at too great a detriment of interpretability. [5] Analyzed a set of model performances on NBA data and found that tree-based models such as random forests outperformed non-tree alternatives. Furthermore, a birds-eye analysis of remaining League of Legends-based papers reveals a similar story: Random forests and logistic regression often comprise the top performing linear models. 

Three options were chosen to fit and compare for the sake of the project: Random Forest, Logistic Regression, and Support Vector Machine models. Initially, these were fit with a small dataset in order to conserve needed compute time. Models were evaluated with a 70/30 train/test split and 5-fold cv for hyperparameter tunings.

```{r, echo=FALSE}
library(knitr)

kable(
  data.frame(
    `Model Type`      = c("Random Forest", "SVM", "GLM"),
    `Num. Predictors` = c(23, 6, 23),
    `Test Accuracy`   = c("74.7%", "73.5%", "75.1%")
  ),
  format = "latex",
  booktabs = FALSE,
  caption = "Model Evaluation"
)
```

As can be seen above in table 2, the GLM model maintained highest test accuracy, while the SVM model was the lowest. However, the SVM model was trained on 6 predictors ('deaths', 'dragonKills', 'baronKills', 'firstBloodKill', 'firstBloodAssist', 'kills'), whereas GLM was trained on 23. 

The following is the results from the Random Forest model, chosen for its interpretability.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(parsnip)
library(tidymodels)
library(fastshap)

df <- read.csv("data/d2_250_performance.csv")
df <- df[df$lane != "NONE", ]

df <- subset(df, select=-turretsLost)
df <- subset(df, select=-turretTakedowns)

df$position = NULL
df$win <- factor(df$win)

set.seed(67)
nrow <- nrow(df)
index <- sample(1:nrow, size = nrow * 0.7)
train <- df[index, ]
test <- df[-index, ]

rf_spec <-
  rand_forest(
    mtry = tune(),
    min_n = tune(),
    trees = 500
  ) |>
  set_engine("ranger", importance="impurity") |>
  set_mode("classification")

rf_wf <-
  workflow() |>
  add_model(rf_spec) |>
  add_formula(win ~ .)

folds <- vfold_cv(train, v=5, strata=win)

rf_grid <- grid_regular(
  mtry(range = c(2, 10)),
  min_n(range = c(2, 20)),
  levels = 6
)

rf_tuned <- tune_grid(
  rf_wf,
  resamples=folds,
  grid = rf_grid,
  metrics=metric_set(accuracy)
)

rf_results <- collect_metrics(rf_tuned)

best_params <- select_best(rf_tuned, metric="accuracy")
final_rf <- finalize_workflow(rf_wf, best_params)

rf <- fit(final_rf, train)

pred <- predict(rf, new_data=test, type="class")

eval_df <- tibble(
  win = y_test,
  .pred_class = pred$.pred_class
)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
accuracy(eval_df, truth = win, estimate = .pred_class)$.estimate
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
acc_results <- rf_results |> dplyr::filter(.metric == "accuracy")

ggplot(acc_results, aes(x = mtry, y = min_n, fill = mean)) +
  geom_tile() +
  labs(
    title = "5-Fold CV Accuracy for Random Forest",
    x = "mtry",
    y = "min_n",
    fill = "Accuracy"
  )
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tibble)
library(dplyr)

imp <- rf |> extract_fit_engine() |> ranger::importance() |>
  enframe(name="variable", value="importance") |>
  arrange(desc(importance))

library(ggplot2)

ggplot(imp, aes(x = reorder(variable, importance), y = importance)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Random Forest Predictor Importance",
    x = "Predictor",
    y = "Importance"
  ) 

```

As seen above in f4, the random forest model achieves a high prediction accuracy with a similar number of false positives and false negatives. Furthermore, as seen in f3, we can see that deaths and gold earned play a significant role in influencing the outcome of games. First blood kill and some other statistics provide less insight. 

## 2.4 Interpretability

The approach used builds heavily on accurately classifying game outcomes to categorize samples as either win or defeat. However, in order to determine which factors led to the outcome of the match, SHAP (SHapley Additive exPlanations) was used to quantify each feature’s contribution to the model’s predictions. SHAP values provide a game-theoretic interpretation of model behavior by breaking down each each individual prediction into additive contributions from each feature. This allows interpretability in two ways:

- Global interpretability, where SHAP summarizes which features most strongly influence predictions across all matches
- Local interpretability, where SHAP explains why the model predicted a win or loss for a specific match.

A primary advantage of using SHAP over model-specific analysis is that it is agnostic to the type of model being used and also provides more in-depth insights.

Futhermore, by looking at the local prediction for a specific match, we can begin to provide feedback to the player on things to improve. This aligns with the stated goals of this project and will be explored further later in the paper.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(fastshap)

X <- train %>% select(-win)

predict(rf, new_data = head(X), type = "prob") %>% names()

f_fun <- function(object, newdata) {
  newdata <- as.data.frame(newdata)
  predict(object, new_data = newdata, type = "prob") %>%
    dplyr::pull(".pred_True") 
}

set.seed(1)
shap_vals <- fastshap::explain(
  rf,
  X = X,
  pred_wrapper = f_fun,
  nsim = 5
)
```

```{r}
print("Mean impact of deaths on game outcome:")
mean(abs(shap_vals[ ,1]))

```

```{r}
shap_long <- as.data.frame(shap_vals) %>%
  mutate(row_id = row_number()) %>%
  pivot_longer(
    cols = -row_id,
    names_to = "feature",
    values_to = "shap"
  )

feature_order <- shap_long %>%
  group_by(feature) %>%
  summarise(mean_abs_shap = mean(abs(shap), na.rm = TRUE)) %>%
  arrange(mean_abs_shap) %>%
  pull(feature)

shap_long$feature <- factor(shap_long$feature, levels = feature_order)

ggplot(shap_long, aes(x = shap, y = feature)) +
  geom_point(alpha = 0.25) +
  labs(
    title = "SHAP Summary Plot",
    x = "SHAP Value",
    y = "Feature"
  )
```


## 3. Results and Discussion

Model performance across the three supervised approaches shows that logistic regression (GLM) achieved the highest test accuracy at 75.1%, followed closely by the random forest at 74.7%, while the SVM trailed slightly at 73.5%.

Vitally, both SHAP and the random forest internal importance ranking highlight deaths and goldEarned as the two most influential predictors. This is an expected result as the amount of gold earned throughout the course of a match directly leads to the player with high gold earned purchasing more items, and therefore having more frequent access to victory conditions thoughout the match. What is surpising, however, is that the internal estimate from the random forest model holds the total number of deaths as the strongest predictor. Deaths have two primary side-effects throughout the course of the match. First, the enemy player responsible for the death is rewarded with gold, increasing their total gold earned and providing them with more opportunity to engage with victory conditions. However, this relationship is more directly captured with the goldEarned statistic. The second side-effect of a death is that you lose the ability to interact with any aspect of the game for 6-56 seconds (based on level) [riot wiki citation]. This directly impacts the player's presence within the game. In domain-specific terms: deaths decrease your tempo. 

On the other hand, first blood-related statistics were commonly ranked lowest for importance within the models. This suggests that early, isolated advantages do not often lead to determining the match outcome. This is counter to some community sentiment and may be the grounds for future analysis.

## 4. Conclusion

This project demonstrates a pipeline and plausible solution for integrating SHAP and machine learning maodels to create interpretable, actionable insights about League of Legends match wins. WOrking with a high-level dataset, all three models got high predictive accuracy (even when compared to similar projects in the same area). Vitally, SHAP provided a highly detailed and robust vision of the key parts of the dataset, identifying gold, kills, deaths, vision control and infulential factors and first blood statistics as non-influential. 

The hope is that the work done in this project can help form a foundation for future market-targeted platforms such as analytical systems to support competitive teams in esports, automated coaching for players, or personalized platforms such as the already existent mobalytics.gg. 
  
## References

[1] Zamri, M. Asyhraf Zamir, et al. “Online Game Outcome Prediction Model Using Weighted-Based Feature Approach.” Fusion: Practice and Applications (FPA), vol. 15, no. 2, 2024, pp. 132–144. DOI: https://doi.org/10.54216/FPA.150212

[2] J. A. Hitar-García, L. Morán-Fernández and V. Bolón-Canedo, "Machine Learning Methods for Predicting League of Legends Game Outcome," in IEEE Transactions on Games, vol. 15, no. 2, pp. 171-181, June 2023, doi: 10.1109/TG.2022.3153086.

[3] https://github.com/reneleogp/ML-Prediction-LoL

[4] Antonio Luis Cardoso Silva et al. "Continuous Outcome Prediction of League of Legends Competitive Matches Using Recurrent Neural Networks." (2018).

[5] https://link.springer.com/content/pdf/10.1007/s10115-024-02092-9.pdf